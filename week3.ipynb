{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "- How many samples are there in the dataset?\n",
    "- How many features are there per sample, excluding the class/type label?\n",
    "- Print the number of unique classes (i.e., fruit types), list the class names, and their frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 35)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# There are 898 samples/rows\n",
    "# There are 35 features/columns\n",
    "df = pd.read_excel('datasets/Date_Fruit_Datasets.xlsx',sheet_name=\"Date_Fruit_Datasets\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The nunique() method returns the number of unique values for each column.\n",
    "# There are 7 unique values in the \"Class\" column\n",
    "df['Class'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BERHI', 'DEGLET', 'DOKOL', 'IRAQI', 'ROTANA', 'SAFAVI', 'SOGAY'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of unique values in 'Class' column\n",
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "DOKOL     204\n",
       "SAFAVI    199\n",
       "ROTANA    166\n",
       "DEGLET     98\n",
       "SOGAY      94\n",
       "IRAQI      72\n",
       "BERHI      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "- List mean, stdev, min, max of each of the features in the dataset\n",
    "\n",
    "- The **describe()** method returns description of the data in the DataFrame.\n",
    "    - If the DataFrame contains numerical data, the description contains these information for each column:\n",
    "        - count - The number of not-empty values.\n",
    "        - mean - The average (mean) value.\n",
    "        - std - The standard deviation.\n",
    "        - min - the minimum value.\n",
    "        - 25% - The 25% percentile*.\n",
    "        - 50% - The 50% percentile*.\n",
    "        - 75% - The 75% percentile*.\n",
    "        - max - the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>SkewRB</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>8.980000e+02</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>298295.207127</td>\n",
       "      <td>2057.660953</td>\n",
       "      <td>750.811994</td>\n",
       "      <td>495.872785</td>\n",
       "      <td>0.737468</td>\n",
       "      <td>604.577938</td>\n",
       "      <td>0.981840</td>\n",
       "      <td>303845.592428</td>\n",
       "      <td>0.736267</td>\n",
       "      <td>2.131102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250518</td>\n",
       "      <td>4.247845</td>\n",
       "      <td>5.110894</td>\n",
       "      <td>3.780928</td>\n",
       "      <td>-3.185021e+10</td>\n",
       "      <td>-2.901860e+10</td>\n",
       "      <td>-2.771876e+10</td>\n",
       "      <td>50.082888</td>\n",
       "      <td>48.805681</td>\n",
       "      <td>48.098393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107245.205337</td>\n",
       "      <td>410.012459</td>\n",
       "      <td>144.059326</td>\n",
       "      <td>114.268917</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>119.593888</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>108815.656947</td>\n",
       "      <td>0.053745</td>\n",
       "      <td>17.820778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632918</td>\n",
       "      <td>2.892357</td>\n",
       "      <td>3.745463</td>\n",
       "      <td>2.049831</td>\n",
       "      <td>2.037241e+10</td>\n",
       "      <td>1.712952e+10</td>\n",
       "      <td>1.484137e+10</td>\n",
       "      <td>16.063125</td>\n",
       "      <td>14.125911</td>\n",
       "      <td>10.813862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987.000000</td>\n",
       "      <td>911.828000</td>\n",
       "      <td>336.722700</td>\n",
       "      <td>2.283200</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>50.298400</td>\n",
       "      <td>0.836600</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>1.065300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029100</td>\n",
       "      <td>1.708200</td>\n",
       "      <td>1.607600</td>\n",
       "      <td>1.767200</td>\n",
       "      <td>-1.091224e+11</td>\n",
       "      <td>-9.261697e+10</td>\n",
       "      <td>-8.747177e+10</td>\n",
       "      <td>15.191100</td>\n",
       "      <td>20.524700</td>\n",
       "      <td>22.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>206948.000000</td>\n",
       "      <td>1726.091500</td>\n",
       "      <td>641.068650</td>\n",
       "      <td>404.684375</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>513.317075</td>\n",
       "      <td>0.978825</td>\n",
       "      <td>210022.750000</td>\n",
       "      <td>0.705875</td>\n",
       "      <td>1.373725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>2.536625</td>\n",
       "      <td>2.508850</td>\n",
       "      <td>2.577275</td>\n",
       "      <td>-4.429444e+10</td>\n",
       "      <td>-3.894638e+10</td>\n",
       "      <td>-3.564534e+10</td>\n",
       "      <td>38.224425</td>\n",
       "      <td>38.654525</td>\n",
       "      <td>39.250725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>319833.000000</td>\n",
       "      <td>2196.345450</td>\n",
       "      <td>791.363400</td>\n",
       "      <td>495.054850</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>638.140950</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>327207.000000</td>\n",
       "      <td>0.746950</td>\n",
       "      <td>1.524150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135550</td>\n",
       "      <td>3.069800</td>\n",
       "      <td>3.127800</td>\n",
       "      <td>3.080700</td>\n",
       "      <td>-2.826156e+10</td>\n",
       "      <td>-2.620990e+10</td>\n",
       "      <td>-2.392928e+10</td>\n",
       "      <td>53.841300</td>\n",
       "      <td>50.337800</td>\n",
       "      <td>49.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>382573.000000</td>\n",
       "      <td>2389.716575</td>\n",
       "      <td>858.633750</td>\n",
       "      <td>589.031700</td>\n",
       "      <td>0.802150</td>\n",
       "      <td>697.930525</td>\n",
       "      <td>0.991800</td>\n",
       "      <td>388804.000000</td>\n",
       "      <td>0.775850</td>\n",
       "      <td>1.674750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593950</td>\n",
       "      <td>4.449850</td>\n",
       "      <td>7.320400</td>\n",
       "      <td>4.283125</td>\n",
       "      <td>-1.460482e+10</td>\n",
       "      <td>-1.433105e+10</td>\n",
       "      <td>-1.660367e+10</td>\n",
       "      <td>63.063350</td>\n",
       "      <td>59.573600</td>\n",
       "      <td>56.666675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>546063.000000</td>\n",
       "      <td>2811.997100</td>\n",
       "      <td>1222.723000</td>\n",
       "      <td>766.453600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>833.827900</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>552598.000000</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>535.525700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.092300</td>\n",
       "      <td>26.171100</td>\n",
       "      <td>26.736700</td>\n",
       "      <td>32.249500</td>\n",
       "      <td>-1.627316e+08</td>\n",
       "      <td>-5.627727e+08</td>\n",
       "      <td>-4.370435e+08</td>\n",
       "      <td>79.828900</td>\n",
       "      <td>83.064900</td>\n",
       "      <td>74.104600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AREA    PERIMETER   MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY  \\\n",
       "count     898.000000   898.000000   898.000000  898.000000    898.000000   \n",
       "mean   298295.207127  2057.660953   750.811994  495.872785      0.737468   \n",
       "std    107245.205337   410.012459   144.059326  114.268917      0.088727   \n",
       "min      1987.000000   911.828000   336.722700    2.283200      0.344800   \n",
       "25%    206948.000000  1726.091500   641.068650  404.684375      0.685625   \n",
       "50%    319833.000000  2196.345450   791.363400  495.054850      0.754700   \n",
       "75%    382573.000000  2389.716575   858.633750  589.031700      0.802150   \n",
       "max    546063.000000  2811.997100  1222.723000  766.453600      1.000000   \n",
       "\n",
       "          EQDIASQ    SOLIDITY    CONVEX_AREA      EXTENT  ASPECT_RATIO  ...  \\\n",
       "count  898.000000  898.000000     898.000000  898.000000    898.000000  ...   \n",
       "mean   604.577938    0.981840  303845.592428    0.736267      2.131102  ...   \n",
       "std    119.593888    0.018157  108815.656947    0.053745     17.820778  ...   \n",
       "min     50.298400    0.836600    2257.000000    0.512300      1.065300  ...   \n",
       "25%    513.317075    0.978825  210022.750000    0.705875      1.373725  ...   \n",
       "50%    638.140950    0.987300  327207.000000    0.746950      1.524150  ...   \n",
       "75%    697.930525    0.991800  388804.000000    0.775850      1.674750  ...   \n",
       "max    833.827900    0.997400  552598.000000    0.856200    535.525700  ...   \n",
       "\n",
       "           SkewRB  KurtosisRR  KurtosisRG  KurtosisRB     EntropyRR  \\\n",
       "count  898.000000  898.000000  898.000000  898.000000  8.980000e+02   \n",
       "mean     0.250518    4.247845    5.110894    3.780928 -3.185021e+10   \n",
       "std      0.632918    2.892357    3.745463    2.049831  2.037241e+10   \n",
       "min     -1.029100    1.708200    1.607600    1.767200 -1.091224e+11   \n",
       "25%     -0.196950    2.536625    2.508850    2.577275 -4.429444e+10   \n",
       "50%      0.135550    3.069800    3.127800    3.080700 -2.826156e+10   \n",
       "75%      0.593950    4.449850    7.320400    4.283125 -1.460482e+10   \n",
       "max      3.092300   26.171100   26.736700   32.249500 -1.627316e+08   \n",
       "\n",
       "          EntropyRG     EntropyRB  ALLdaub4RR  ALLdaub4RG  ALLdaub4RB  \n",
       "count  8.980000e+02  8.980000e+02  898.000000  898.000000  898.000000  \n",
       "mean  -2.901860e+10 -2.771876e+10   50.082888   48.805681   48.098393  \n",
       "std    1.712952e+10  1.484137e+10   16.063125   14.125911   10.813862  \n",
       "min   -9.261697e+10 -8.747177e+10   15.191100   20.524700   22.130000  \n",
       "25%   -3.894638e+10 -3.564534e+10   38.224425   38.654525   39.250725  \n",
       "50%   -2.620990e+10 -2.392928e+10   53.841300   50.337800   49.614100  \n",
       "75%   -1.433105e+10 -1.660367e+10   63.063350   59.573600   56.666675  \n",
       "max   -5.627727e+08 -4.370435e+08   79.828900   83.064900   74.104600  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "- Shuffle the data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>298963</td>\n",
       "      <td>2119.7129</td>\n",
       "      <td>722.8275</td>\n",
       "      <td>544.2319</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>616.9696</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>317248</td>\n",
       "      <td>0.6671</td>\n",
       "      <td>1.3282</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7354</td>\n",
       "      <td>6.6662</td>\n",
       "      <td>3.9821</td>\n",
       "      <td>-12710694912</td>\n",
       "      <td>-12882736128</td>\n",
       "      <td>-16103895040</td>\n",
       "      <td>31.6534</td>\n",
       "      <td>32.9280</td>\n",
       "      <td>37.1924</td>\n",
       "      <td>SAFAVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>242106</td>\n",
       "      <td>1897.2180</td>\n",
       "      <td>733.3027</td>\n",
       "      <td>424.0022</td>\n",
       "      <td>0.8159</td>\n",
       "      <td>555.2107</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>244779</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>1.7295</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6340</td>\n",
       "      <td>2.8078</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>-26404036608</td>\n",
       "      <td>-18962182144</td>\n",
       "      <td>-20471883776</td>\n",
       "      <td>50.8506</td>\n",
       "      <td>44.2080</td>\n",
       "      <td>45.5415</td>\n",
       "      <td>DOKOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>451414</td>\n",
       "      <td>2457.2080</td>\n",
       "      <td>889.3253</td>\n",
       "      <td>652.4316</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>758.1281</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>452755</td>\n",
       "      <td>0.7877</td>\n",
       "      <td>1.3631</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0703</td>\n",
       "      <td>3.4163</td>\n",
       "      <td>4.9168</td>\n",
       "      <td>-63711666176</td>\n",
       "      <td>-64060743680</td>\n",
       "      <td>-52603465728</td>\n",
       "      <td>57.8060</td>\n",
       "      <td>58.5449</td>\n",
       "      <td>52.4199</td>\n",
       "      <td>BERHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>315524</td>\n",
       "      <td>2139.2590</td>\n",
       "      <td>777.8326</td>\n",
       "      <td>519.9553</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>633.8278</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>320702</td>\n",
       "      <td>0.7443</td>\n",
       "      <td>1.4960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8627</td>\n",
       "      <td>1.9195</td>\n",
       "      <td>3.3367</td>\n",
       "      <td>-38889222144</td>\n",
       "      <td>-29889806336</td>\n",
       "      <td>-26093897728</td>\n",
       "      <td>51.1594</td>\n",
       "      <td>45.1313</td>\n",
       "      <td>44.8091</td>\n",
       "      <td>SOGAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>353128</td>\n",
       "      <td>2372.9270</td>\n",
       "      <td>936.3535</td>\n",
       "      <td>482.3184</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>670.5345</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>359483</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>1.9414</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2783</td>\n",
       "      <td>8.4092</td>\n",
       "      <td>4.1143</td>\n",
       "      <td>-10767624192</td>\n",
       "      <td>-11673603072</td>\n",
       "      <td>-14728344576</td>\n",
       "      <td>25.4581</td>\n",
       "      <td>27.4244</td>\n",
       "      <td>32.6198</td>\n",
       "      <td>SAFAVI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "645  298963  2119.7129    722.8275    544.2319        0.6581  616.9696   \n",
       "224  242106  1897.2180    733.3027    424.0022        0.8159  555.2107   \n",
       "6    451414  2457.2080    889.3253    652.4316        0.6796  758.1281   \n",
       "854  315524  2139.2590    777.8326    519.9553        0.7437  633.8278   \n",
       "692  353128  2372.9270    936.3535    482.3184        0.8571  670.5345   \n",
       "\n",
       "     SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n",
       "645    0.9424       317248  0.6671        1.3282  ...      8.7354      6.6662   \n",
       "224    0.9891       244779  0.7937        1.7295  ...      2.6340      2.8078   \n",
       "6      0.9970       452755  0.7877        1.3631  ...      3.0703      3.4163   \n",
       "854    0.9839       320702  0.7443        1.4960  ...      1.8627      1.9195   \n",
       "692    0.9823       359483  0.6619        1.9414  ...     10.2783      8.4092   \n",
       "\n",
       "     KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  \\\n",
       "645      3.9821 -12710694912 -12882736128 -16103895040     31.6534   \n",
       "224      2.5781 -26404036608 -18962182144 -20471883776     50.8506   \n",
       "6        4.9168 -63711666176 -64060743680 -52603465728     57.8060   \n",
       "854      3.3367 -38889222144 -29889806336 -26093897728     51.1594   \n",
       "692      4.1143 -10767624192 -11673603072 -14728344576     25.4581   \n",
       "\n",
       "     ALLdaub4RG  ALLdaub4RB   Class  \n",
       "645     32.9280     37.1924  SAFAVI  \n",
       "224     44.2080     45.5415   DOKOL  \n",
       "6       58.5449     52.4199   BERHI  \n",
       "854     45.1313     44.8091   SOGAY  \n",
       "692     27.4244     32.6198  SAFAVI  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled = df.sample(frac=1)\n",
    "data_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "- Split the dataset into training (80%) and test (20%)\n",
    "    - Splitting your dataset into training and testing sets allows you to evaluate your model's performance accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 35)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 35)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of rows\n",
    "nrow = len(df)\n",
    "# split the data at 80\n",
    "split = int(nrow * 0.80)\n",
    "# training set is the data shuffled from 0 to 80\n",
    "# .iloc[] is an indexer used for integer-location-based indexing of data in a DataFrame. \n",
    "training_set = data_shuffled.iloc[:split]\n",
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 35)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set is the data shuffled from 80 to 100\n",
    "test_set = data_shuffled.iloc[split:]\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "- Scale all independent features.\n",
    "    - **Scaling** data into new values makes it easier to compare, especially when the data is in different units of measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, 34)\n",
      "(180, 34)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# features = x\n",
    "# label =  y\n",
    "# the features are all the columns besides class \n",
    "# because this is the information needed in order to predict/classify the class\n",
    "train_set_x = training_set.drop(columns=['Class'])\n",
    "test_set_x = test_set.drop(columns=['Class'])\n",
    "# initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit the scaler to the sets\n",
    "scaler.fit(train_set_x)\n",
    "# transform the numerical data\n",
    "scaled_training_x = scaler.transform(train_set_x)\n",
    "scaled_testing_x = scaler.transform(test_set_x)\n",
    "\n",
    "print(scaled_training_x.shape)\n",
    "print(scaled_testing_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "- Build a classifier with the training set.\n",
    "- \"**Classification** is a supervised machine learning method where the model tries to predict the correct label of a given input data. \n",
    "- In classification, the model is fully trained using the training data, and then it is evaluated on test data before being used to perform prediction on new unseen data.\"\n",
    "- A **label** is a column used for supervised learning\n",
    "- **Features** are the values/set of columns that a supervised model uses to predict the label. The **label** is the \"answer,\" or the value we want the model to predict\n",
    "- EX: Spam email detection: Given a set of scam and non-scam emails the model is tested on how well it can label the scam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718,)\n",
      "(180,)\n",
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# the label is Class because this is the column the model is trying to predict\n",
    "# encode,fit, and transform the label\n",
    "train_set_y = training_set['Class']\n",
    "test_set_y = test_set['Class']\n",
    "# LabelEncoder() is used for encoding categorical labels into numerical values.\n",
    "le = LabelEncoder()\n",
    "# The fit method is used to train a machine learning model on a dataset. \n",
    "# It takes in a dataset and a set of labels, and then fits the model to the data.\n",
    "le.fit(train_set_y)\n",
    "\n",
    "encoded_training_y = le.transform(train_set_y)\n",
    "encoded_testing_y = le.transform(test_set_y)\n",
    "print(encoded_training_y.shape)\n",
    "print(encoded_testing_y.shape)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X=scaled_training_x, y=encoded_training_y )\n",
    "pred = model.predict(scaled_testing_x)\n",
    "\n",
    "accuracy = accuracy_score(encoded_testing_y, pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X=scaled_training_x, y=encoded_training_y )\n",
    "pred = model.predict(scaled_testing_x)\n",
    "\n",
    "accuracy = accuracy_score(encoded_testing_y, pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X=scaled_training_x, y=encoded_training_y )\n",
    "pred = model.predict(scaled_testing_x)\n",
    "\n",
    "accuracy = accuracy_score(encoded_testing_y, pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8944444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X=scaled_training_x, y=encoded_training_y )\n",
    "pred = model.predict(scaled_testing_x)\n",
    "\n",
    "accuracy = accuracy_score(encoded_testing_y, pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "- Predict class label of just one sample picked from the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label 1\n",
      "actual_label 1\n"
     ]
    }
   ],
   "source": [
    "sample_x = scaled_testing_x[1]\n",
    "sample_x = sample_x.reshape(1,-1)\n",
    "\n",
    "predicted_label = model.predict(sample_x)\n",
    "\n",
    "actual_label = encoded_testing_y[1]\n",
    "\n",
    "print(\"predicted_label\", predicted_label.item())\n",
    "print('actual_label', actual_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "- Evaluate the model performance based on the test set.\n",
    "- So far, Random Forest and Gradient Boosting have the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.8465616732800196\n",
      "R-squared error = 0.787664029994056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(f'RMSE = {np.sqrt(mean_squared_error(encoded_testing_y, pred))}')\n",
    "print(f'R-squared error = {r2_score(encoded_testing_y, pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of Building an Effection Classification Model\n",
    "### Step 1: Define the Problem\n",
    "- Understand what you want to accomplish with your classification model.\n",
    "- For ex, if the data set consists of spam emails and non-spam emails, the goal might be scam email classification\n",
    "\n",
    "### Step 2: Gather and Preprocess the Data\n",
    "- Shuffle the data\n",
    "- Split it into a training and testing set\n",
    "- only fit the TRAINING set\n",
    "- BOTH the sets will be transformed and scaled\n",
    "- x is the independent variable \n",
    "- y is the dependent \n",
    "\n",
    "### Step 3: Feature Selection and Engineering\n",
    "- Features are going to be the columns that a supervised model uses to predict the label (Emails: Spam and non-spam emails)\n",
    "- A label is the column that the supervised model is trying to predict (Class: spam or non-spam)\n",
    "- X-axis = features\n",
    "- Y-axis = label\n",
    "\n",
    "### Step 4: Choose a model (Supervised learning)\n",
    "- There are many models to choose from:\n",
    "    - Random Forest \n",
    "    - Support Vector Machines\n",
    "    - Neural Networks\n",
    "    - Gradient Boosting \n",
    "    - Logistic Regression\n",
    "    - Decision Trees\n",
    "    - etc.\n",
    "- Fit the scaled training set(X) and encoded training set(Y) for the x and y values\n",
    "- predict the model with the scaled TEST set (x)\n",
    "\n",
    "### Step 5: Evaluate the Model\n",
    "- Calculate the report accuracy, precision, recall, f1-score, false-discovery rate, matthews correlation coefficient of the set.\n",
    "\n",
    "\n",
    "- How to evaluate a REGRESSION model\n",
    "    - Mean squared error (MSE)\n",
    "        - MSE = np.sum((test_y_set - pred)**2)/len(test_set_y)\n",
    "    - Root mean sqaured error\n",
    "        - RMSE = bp.sqrt(MSE)\n",
    "    - or use the libraries \n",
    "        - from sklearn.metrics import mean_squared_error\n",
    "        - from sklearn.metrics import r2_score\n",
    "        - RMSE = np.sqrt(mean_squared_error(test_set_y, pred))\n",
    "    - Mean Absolute Error (MAE) \n",
    "        - least absolute differences = (test_set_y - pred)\n",
    "        - MAE = np.sum(np.abs(test_set_y - pred))/len(test_set_y)\n",
    "        - or use the library \n",
    "    - R2 Score\n",
    "        - 1 - (your model/mean model )\n",
    "        - your_model = np.sum((test_set_y)**2)\n",
    "        - mean_model = np.mean((test_set_y -np.mean(test_set_y)) **2)\n",
    "        - mean model = the higher the number(closer to 1), the lower R2 is \n",
    "                    = the lower(0-1), the higher R2 is  \n",
    "                    = less than 0, worst\n",
    "        - R2 = (1 - (your_model/ mean_model))\n",
    "        - or import the library r2_score\n",
    "        - best R2 score is 1\n",
    "\n",
    "    - Adjusted R2 score only applies if you have many independent features\n",
    "        - 1 - ((1-R2)(n-1)/ (n-p-1))\n",
    "        - P = number of independent features\n",
    "        - n = num of samples\n",
    "        - if tuple is (24016,1)\n",
    "        - p = 1\n",
    "        - n = 24016\n",
    "    - Regression line \n",
    "        - y = f(x1,x2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-week1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
